
üìÑ UNIVERSAL AI-DRIVEN ROOT CAUSE ANALYSIS (RCA) SYSTEM ‚Äì FINAL BUILD INSTRUCTIONS FOR REPLIT AGENT

üö´ STRICT ENFORCEMENT: NO HARDCODING POLICY
Under no circumstances must any part of the RCA system hardcode:
- Equipment Groups / Types / Subtypes
- Failure Modes or Component-Specific Logic
- Symptom Keywords or Equipment Templates

All logic must be **dynamically generated**, **schema-driven**, and **AI/NLP inferred**, as outlined below.

---------------------------------------------------------------------------------------------------
üß† RCA FLOW LOGIC (MUST BE IMPLEMENTED AS UNIVERSAL ENGINE)
---------------------------------------------------------------------------------------------------

1Ô∏è‚É£ INCIDENT ENTRY (User provides natural-language failure description)
   - Example: ‚ÄúPump seal is leaking continuously. No unusual noise.‚Äù
   - System logs Incident ID and stores initial description.

2Ô∏è‚É£ NLP-BASED SYMPTOM EXTRACTION (DO NOT HARDCODE WORDS)
   - Use OpenAI GPT (or custom NLP parser) to extract key technical phrases.
   - Example extracted terms: "seal", "leaking", "continuous", "flush", "pump"

3Ô∏è‚É£ AI-BACKEND RCA INFERENCE ENGINE
   - Prompt AI internally:
     ‚ÄúWhat are the likely causes of [incident description] for [group/type/subtype] equipment?‚Äù
   - AI responds with dynamic, logical failure hypotheses (e.g. seal face wear, flush failure, misalignment, etc.)
   - These are **not loaded from a list**, but dynamically inferred.

4Ô∏è‚É£ MATCH AGAINST EVIDENCE LIBRARY (Optional Filter Layer)
   - For each AI-inferred cause, check if there‚Äôs a matching row in Evidence Library.
   - If found ‚Üí include related evidence requirements, prompt questions, detection gaps.
   - If not found ‚Üí proceed anyway if AI‚Äôs confidence in the cause is ‚â• 90%.
   - ‚ö†Ô∏è Evidence Library must NEVER override AI unless AI confidence < 90%.

5Ô∏è‚É£ GENERATE DYNAMIC EVIDENCE REQUEST PROMPTS
   For each inferred cause:
   - Ask targeted question (e.g., ‚ÄúWas the seal flush pressure normal?‚Äù)
   - Prompt for specific evidence (e.g., IR scan, vibration trend, alignment report)
   - User selects:
     - ‚úÖ Provided (uploads file)
     - ‚ùå Not available
     - üîÑ Will upload later

6Ô∏è‚É£ ANALYZE THE FILE (VIA AI OR CODE LOGIC)
   - System checks content of uploaded file.
   - If insufficient, AI says: ‚ÄúTrend data is unclear ‚Äì please provide clearer file or DCS tag log.‚Äù
   - If supports hypothesis, AI says: ‚ÄúFlush pressure abnormality confirmed. Supports root cause with 83% confidence.‚Äù

7Ô∏è‚É£ ROOT CAUSE DETERMINATION LAYER (UNIVERSAL LOGIC)
   - Based on evidence sufficiency + pattern match:
     - Declare Primary Cause
     - List Contributing Factors (if multiple causes have partial evidence)
     - List Latent Cause (from known procedural/design gaps)

8Ô∏è‚É£ EVIDENCE GAP / DEGRADATION LOGIC
   - If key evidence is not available or unclear:
     - Warn the user (e.g., ‚ÄúUnable to validate misalignment hypothesis due to missing vibration spectrum.‚Äù)
     - Report degraded confidence (e.g., ‚ÄúRCA confidence: 45% - inconclusive without time waveform.‚Äù)
   - System must NEVER generate fake conclusions from junk files.

9Ô∏è‚É£ OUTPUT RCA REPORT (STRUCTURED)
   - Show:
     - Selected failure mode(s)
     - Supporting evidence and analysis result
     - Confidence levels
     - Unanswered prompts
     - Attachments used
     - Recommendation(s)

---------------------------------------------------------------------------------------------------
üìå ADDITIONAL TECHNICAL NOTES
---------------------------------------------------------------------------------------------------

‚úÖ Must use universal schema from Evidence Library:
- Group / Type / Subtype
- FaultSignaturePattern
- Required Trend Data
- AI Prompt Field (optional)
- Evidence Priority, Confidence, Gap Flag

‚úÖ Logging:
- Store each decision as JSON audit object:
  {
    incidentId: ‚Äú123‚Äù,
    cause: ‚ÄúSeal face wear‚Äù,
    keywordMatched: [‚Äúseal‚Äù, ‚Äúdrip‚Äù],
    evidence: ‚ÄúIR scan‚Äù,
    result: ‚ÄúConfirmed‚Äù,
    confidence: 84%
  }

‚úÖ Enforcement Checks:
- No fallback to preloaded equipment templates
- No hardcoded lists of failure modes per equipment
- All logic must begin from user-entered incident + NLP
- All evidence must be validated before inference
- Evidence Library supports, but does not dictate root cause

---------------------------------------------------------------------------------------------------
‚úÖ SUMMARY: DO THIS
---------------------------------------------------------------------------------------------------

‚úÖ Use AI to dynamically infer failure causes per incident
‚úÖ Prompt user only for relevant data per inferred cause
‚úÖ Validate evidence logically before root cause decision
‚úÖ Allow AI to override Library if 90%+ confident
‚úÖ Structure all output with JSON/audit/traceable formats

---------------------------------------------------------------------------------------------------
üö´ NEVER DO THIS
---------------------------------------------------------------------------------------------------

‚ùå Never hardcode failure mode lists for specific equipment
‚ùå Never show prompts for all failure modes at once
‚ùå Never generate final analysis from junk/unreadable data
‚ùå Never let equipment group/type/subtype drive logic directly

---------------------------------------------------------------------------------------------------
üì§ FILE HANDOVER: Build from where system is today (as seen in current app), but apply this full logic layer.
